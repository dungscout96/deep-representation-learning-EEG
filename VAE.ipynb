{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mathematical-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import webdataset as wds\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "framed-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "def selectLabel(x,lbl):\n",
    "    # function to select desired label\n",
    "    lbl_idx = [\"id\",\"sex\",\"age\",\"handedness\",\"index\"].index(lbl.lower())\n",
    "    x = x.decode(\"utf-8\").split(\",\")[lbl_idx]\n",
    "    return x if lbl_idx == 0 else float(x)\n",
    "\n",
    "def add_chan_dim(x):\n",
    "    x = torch.tensor(x)\n",
    "#     x = torch.transpose(x, 0, 1)\n",
    "    return torch.unsqueeze(x,0)\n",
    "\n",
    "class Logger():\n",
    "    def __init__(self, mode='log'):\n",
    "        self.mode = mode\n",
    "        \n",
    "    def set_model_save_location(self, model_dir):\n",
    "        self.model_dir = f\"saved-model/{model_dir}\"\n",
    "        \n",
    "    def set_experiment(self, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        log_format = '%(asctime)s %(message)s'\n",
    "        logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                            format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "        fh = logging.FileHandler(os.path.join('training-logs', f'log-{experiment_name}-{datetime.datetime.today()}.txt'))\n",
    "        fh.setFormatter(logging.Formatter(log_format))\n",
    "        logging.getLogger().addHandler(fh)\n",
    "        self.writer = SummaryWriter(f\"runs/{experiment_name}\")\n",
    "            \n",
    "    def log(self, message=\"\"):\n",
    "        if self.mode == 'log':\n",
    "            logging.info(message)\n",
    "        elif self.mode == 'debug':\n",
    "            print(message)\n",
    "\n",
    "    def save_model(self, model, info):\n",
    "        torch.save(model.state_dict(), f\"{self.model_dir}/model-{self.experiment_name}-{info}\")\n",
    "        \n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "violent-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_train.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "train_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")\n",
    "\n",
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_val.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "val_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ignored-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        encoder_l = [self.encoder_conv_block(True)]\n",
    "        for i in range(2):\n",
    "            encoder_l.append(self.encoder_conv_block())\n",
    "        encoder_l.append(self.encoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        encoder_l.append(nn.Flatten())\n",
    "        encoder_l.append(self.encoder_linear_block(960, 10))\n",
    "        self.encoder = nn.ModuleList(encoder_l)\n",
    "                            \n",
    "        decoder_l = [self.decoder_linear_block(10, 960)]\n",
    "        decoder_l.append(self.decoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        for i in range(2):\n",
    "            decoder_l.append(self.decoder_conv_block())\n",
    "        decoder_l.append(self.decoder_conv_block(True))\n",
    "        self.decoder = nn.ModuleList(decoder_l)\n",
    "    \n",
    "    def encoder_conv_block(self, is_start=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_start:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(1, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    def encoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def decoder_conv_block(self, is_last=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_last:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, 1, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def decoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for f in self.encoder:\n",
    "            x = f(x)\n",
    "        x = self.decoder[0](x)\n",
    "        x = x.view(-1, 32, 1, 30)\n",
    "        for i in range(1,len(self.decoder)):\n",
    "            f = self.decoder[i]\n",
    "            x = f(x)            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39cb173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "         Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "             Conv2d-1     [1, 32, 12, 128]           1,184           1,184\n",
      "               ReLU-2     [1, 32, 12, 128]               0               0\n",
      "             Conv2d-3       [1, 32, 6, 64]          36,896          36,896\n",
      "               ReLU-4       [1, 32, 6, 64]               0               0\n",
      "             Conv2d-5       [1, 32, 3, 32]          36,896          36,896\n",
      "               ReLU-6       [1, 32, 3, 32]               0               0\n",
      "             Conv2d-7       [1, 32, 1, 30]           9,248           9,248\n",
      "               ReLU-8       [1, 32, 1, 30]               0               0\n",
      "            Flatten-9             [1, 960]               0               0\n",
      "            Linear-10              [1, 10]           9,610           9,610\n",
      "              ReLU-11              [1, 10]               0               0\n",
      "            Linear-12             [1, 960]          10,560          10,560\n",
      "              ReLU-13             [1, 960]               0               0\n",
      "   ConvTranspose2d-14       [1, 32, 3, 32]           9,248           9,248\n",
      "              ReLU-15       [1, 32, 3, 32]               0               0\n",
      "   ConvTranspose2d-16       [1, 32, 6, 64]          36,896          36,896\n",
      "              ReLU-17       [1, 32, 6, 64]               0               0\n",
      "   ConvTranspose2d-18     [1, 32, 12, 128]          36,896          36,896\n",
      "              ReLU-19     [1, 32, 12, 128]               0               0\n",
      "   ConvTranspose2d-20      [1, 1, 24, 256]           1,153           1,153\n",
      "              ReLU-21      [1, 1, 24, 256]               0               0\n",
      "===========================================================================\n",
      "Total params: 188,587\n",
      "Trainable params: 188,587\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vae = VAE()\n",
    "from pytorch_model_summary import summary\n",
    "print(summary(vae, torch.zeros((1, 1, 24, 256)), show_input=False))\n",
    "# print(vae(torch.zeros(1,1,24,256)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48aa32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader_train, optimizer, loader_val, epochs, logger, device, dtype):\n",
    "    \"\"\" \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    - logger: Logger object for logging purpose\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    num_batch = len(list(iter(loader_train)))\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    print('Begin trainning...')\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x_hat = model(x)\n",
    "            \n",
    "            loss = F.mse_loss(x, x_hat)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                logger.writer.add_scalar(\"Loss/train\", loss.item(), e*num_batch+t)\n",
    "                logger.log('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "#         train_acc = check_accuracy(loader_train, 'train', model, device, dtype, logger)\n",
    "#         logger.writer.add_scalar(\"Acc/train\", train_acc, e)        \n",
    "        # get validation loss\n",
    "#         model.eval()\n",
    "#         val_loss = check_accuracy(loader_val, 'val', model, device, dtype, logger)\n",
    "#         logger.writer.add_scalar(\"Acc/valid\", val_acc, e)        \n",
    "#         logger.log()\n",
    "        \n",
    "        # Save model per fixed epoch interval\n",
    "        if e > 0 and e % 10 == 0:\n",
    "            logger.save_model(model,f\"epoch{e}\")\n",
    "#         elif val_acc >= 0.83:\n",
    "#             logger.save_model(model,f\"valacc83-epoch{e}\")\n",
    "#         elif val_acc >= 0.84:\n",
    "#             logger.save_model(model,f\"valacc84-epoch{e}\")\n",
    "    # save final model\n",
    "    logger.save_model(model,f\"epoch{e}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54ec2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin trainning...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Logger' object has no attribute 'writer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d40d4f71819a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fb137089f2c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, optimizer, loader_val, epochs, logger, device, dtype)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d, Iteration %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         train_acc = check_accuracy(loader_train, 'train', model, device, dtype, logger)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Logger' object has no attribute 'writer'"
     ]
    }
   ],
   "source": [
    "logger = Logger()\n",
    "logger.set_model_save_location('VAE')\n",
    "seed = 0\n",
    "experiment = f'VAE-seed{seed}'\n",
    "# logger.set_experiment(experiment)\n",
    "\n",
    "batch_size = 16\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size)\n",
    "loader_val = DataLoader(val_data, batch_size=batch_size)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.0001)\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train(vae, loader_train, optimizer, loader_val, 100, logger, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_W(W, F, P, S):\n",
    "    return np.floor((W - F + 2*P)/S + 1)\n",
    "\n",
    "W = 256\n",
    "for i in range(3):\n",
    "    W = out_W(W, 6, 2, 2)\n",
    "\n",
    "print(W)\n",
    "print(out_W(W, 3, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
