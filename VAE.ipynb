{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mathematical-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import webdataset as wds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "framed-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectLabel(x,lbl):\n",
    "    # function to select desired label\n",
    "    lbl_idx = [\"id\",\"sex\",\"age\",\"handedness\",\"index\"].index(lbl.lower())\n",
    "    x = x.decode(\"utf-8\").split(\",\")[lbl_idx]\n",
    "    return x if lbl_idx == 0 else float(x)\n",
    "\n",
    "def add_chan_dim(x):\n",
    "    x = torch.tensor(x)\n",
    "#     x = torch.transpose(x, 0, 1)\n",
    "    return torch.unsqueeze(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "violent-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_train.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "train_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")\n",
    "\n",
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_val.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "val_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ignored-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        encoder_l = [self.encoder_conv_block(True)]\n",
    "        for i in range(2):\n",
    "            encoder_l.append(self.encoder_conv_block())\n",
    "        encoder_l.append(self.encoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        encoder_l.append(nn.Flatten())\n",
    "        encoder_l.append(self.encoder_linear_block(960, 10))\n",
    "        self.encoder = nn.ModuleList(encoder_l)\n",
    "                            \n",
    "        decoder_l = [self.decoder_linear_block(10, 960)]\n",
    "        decoder_l.append(self.decoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        for i in range(2):\n",
    "            decoder_l.append(self.decoder_conv_block())\n",
    "        decoder_l.append(self.decoder_conv_block(True))\n",
    "        self.decoder = nn.ModuleList(decoder_l)\n",
    "    \n",
    "    def encoder_conv_block(self, is_start=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_start:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(1, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    def encoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def decoder_conv_block(self, is_last=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_last:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, 1, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def decoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for f in self.encoder:\n",
    "            x = f(x)\n",
    "        x = self.decoder[0](x)\n",
    "        x = x.view(-1, 32, 1, 30)\n",
    "        for i in range(1,len(self.decoder)):\n",
    "            f = self.decoder[i]\n",
    "            x = f(x)            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c39cb173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=960, out_features=10, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=960, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(32, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ConvTranspose2d(32, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): ConvTranspose2d(32, 1, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = VAE()\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "49c97c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 24, 256])\n"
     ]
    }
   ],
   "source": [
    "print(vae(torch.zeros(1,1,24,256)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_W(W, F, P, S):\n",
    "    return np.floor((W - F + 2*P)/S + 1)\n",
    "\n",
    "W = 256\n",
    "for i in range(3):\n",
    "    W = out_W(W, 6, 2, 2)\n",
    "\n",
    "print(W)\n",
    "print(out_W(W, 3, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
