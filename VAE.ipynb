{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mathematical-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import webdataset as wds\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "framed-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "def selectLabel(x,lbl):\n",
    "    # function to select desired label\n",
    "    lbl_idx = [\"id\",\"sex\",\"age\",\"handedness\",\"index\"].index(lbl.lower())\n",
    "    x = x.decode(\"utf-8\").split(\",\")[lbl_idx]\n",
    "    return x if lbl_idx == 0 else float(x)\n",
    "\n",
    "def add_chan_dim(x):\n",
    "    x = torch.tensor(x)\n",
    "#     x = torch.transpose(x, 0, 1)\n",
    "    return torch.unsqueeze(x,0)\n",
    "\n",
    "class Logger():\n",
    "    def __init__(self, mode='log'):\n",
    "        self.mode = mode\n",
    "        \n",
    "    def set_model_save_location(self, model_dir):\n",
    "        self.model_dir = f\"saved-model/{model_dir}\"\n",
    "        \n",
    "    def set_experiment(self, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        log_format = '%(asctime)s %(message)s'\n",
    "        logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                            format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "        fh = logging.FileHandler(os.path.join('training-logs', f'log-{experiment_name}-{datetime.datetime.today()}.txt'))\n",
    "        fh.setFormatter(logging.Formatter(log_format))\n",
    "        logging.getLogger().addHandler(fh)\n",
    "        self.writer = SummaryWriter(f\"runs/{experiment_name}\")\n",
    "            \n",
    "    def log(self, message=\"\"):\n",
    "        if self.mode == 'log':\n",
    "            logging.info(message)\n",
    "        elif self.mode == 'debug':\n",
    "            print(message)\n",
    "\n",
    "    def save_model(self, model, info):\n",
    "        torch.save(model.state_dict(), f\"{self.model_dir}/model-{self.experiment_name}-{info}\")\n",
    "        \n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "violent-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_train.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "train_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")\n",
    "\n",
    "s3_url = 'https://childmind.s3.us-west-1.amazonaws.com/python/childmind_val.tar' # replace 'train' with 'val' and 'test' accordingly\n",
    "val_data = wds.WebDataset(s3_url).decode().map_dict(npy=add_chan_dim, cls=lambda x: selectLabel(x,'sex')).to_tuple(\"npy\",\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ignored-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module): \n",
    "    \n",
    "    def __init__(self, latent_dim):\n",
    "        # latent_dim: dimension of the latent representation vector\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        encoder_l = [self.encoder_conv_block(True)]\n",
    "        for i in range(2):\n",
    "            encoder_l.append(self.encoder_conv_block())\n",
    "        encoder_l.append(self.encoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        encoder_l.append(nn.Flatten())\n",
    "        self.encoder_before_last = nn.ModuleList(encoder_l)\n",
    "        self.encoder_mu = self.encoder_linear_block(960,10)\n",
    "        self.encoder_sigma = self.encoder_linear_block(960, latent_dim)\n",
    "                            \n",
    "        decoder_l = [self.decoder_linear_block(latent_dim, 960)]\n",
    "        decoder_l.append(self.decoder_conv_block(False, 32, 32, 3, 1, 0))\n",
    "        for i in range(2):\n",
    "            decoder_l.append(self.decoder_conv_block())\n",
    "        decoder_l.append(self.decoder_conv_block(True))\n",
    "        self.decoder = nn.ModuleList(decoder_l)\n",
    "    \n",
    "    def encoder_conv_block(self, is_start=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_start:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(1, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    def encoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def decoder_conv_block(self, is_last=False, in_channels=32, out_channels=32, kernel_size=6, stride=2, padding=2):\n",
    "        if is_last:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, 1, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def decoder_linear_block(self, in_chan, out_chan):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_chan, out_chan),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for f in self.encoder_before_last:\n",
    "            x = f(x)\n",
    "\n",
    "        mu = self.encoder_mu(x)\n",
    "        sigma = self.encoder_sigma(x)\n",
    "        z = self.sample_z(mu, sigma)\n",
    "        \n",
    "        x = self.decoder[0](z)\n",
    "        x = x.view(-1, 32, 1, 30) # reshape the tensor to be expected dimension for ConvTranspose\n",
    "        for i in range(1,len(self.decoder)):\n",
    "            f = self.decoder[i]\n",
    "            x = f(x) \n",
    "            \n",
    "        return mu, sigma, x\n",
    "    \n",
    "    def sample_z(self, mu, sigma):\n",
    "        # Input\n",
    "        #     mu:     [batch_size, self.latent_size] the predicted mu value for each sample in the batch\n",
    "        #     sigma:  [batch_size, self.latent_size] the predicted diag elem of sigma value for each sample in the batch\n",
    "        # Output\n",
    "        #     z: [batch_size, self.latent_size] the latent representation of each sample in the batch\n",
    "        # Reference: https://agustinus.kristia.de/techblog/2016/12/10/variational-autoencoder/\n",
    "        \n",
    "        # eps ~ N(0,1)        \n",
    "        batch_size = mu.size()[0]\n",
    "        eps = torch.randn((batch_size,1))\n",
    "        z = mu + sigma/2*eps\n",
    "        \n",
    "        return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39cb173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "         Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "===========================================================================\n",
      "             Conv2d-1     [1, 32, 12, 128]           1,184           1,184\n",
      "               ReLU-2     [1, 32, 12, 128]               0               0\n",
      "             Conv2d-3       [1, 32, 6, 64]          36,896          36,896\n",
      "               ReLU-4       [1, 32, 6, 64]               0               0\n",
      "             Conv2d-5       [1, 32, 3, 32]          36,896          36,896\n",
      "               ReLU-6       [1, 32, 3, 32]               0               0\n",
      "             Conv2d-7       [1, 32, 1, 30]           9,248           9,248\n",
      "               ReLU-8       [1, 32, 1, 30]               0               0\n",
      "            Flatten-9             [1, 960]               0               0\n",
      "            Linear-10              [1, 10]           9,610           9,610\n",
      "              ReLU-11              [1, 10]               0               0\n",
      "            Linear-12              [1, 10]           9,610           9,610\n",
      "              ReLU-13              [1, 10]               0               0\n",
      "            Linear-14             [1, 960]          10,560          10,560\n",
      "              ReLU-15             [1, 960]               0               0\n",
      "   ConvTranspose2d-16       [1, 32, 3, 32]           9,248           9,248\n",
      "              ReLU-17       [1, 32, 3, 32]               0               0\n",
      "   ConvTranspose2d-18       [1, 32, 6, 64]          36,896          36,896\n",
      "              ReLU-19       [1, 32, 6, 64]               0               0\n",
      "   ConvTranspose2d-20     [1, 32, 12, 128]          36,896          36,896\n",
      "              ReLU-21     [1, 32, 12, 128]               0               0\n",
      "   ConvTranspose2d-22      [1, 1, 24, 256]           1,153           1,153\n",
      "              ReLU-23      [1, 1, 24, 256]               0               0\n",
      "===========================================================================\n",
      "Total params: 198,197\n",
      "Trainable params: 198,197\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(10)\n",
    "from pytorch_model_summary import summary\n",
    "print(summary(vae, torch.zeros((1, 1, 24, 256)), show_input=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6724f9",
   "metadata": {},
   "source": [
    "KL divergence loss\n",
    "![kl_loss](images/kl_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48aa32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_vae_loss(mu_hat, sigma_hat, x_hat, x_target):\n",
    "    likelihood_loss = F.mse_loss(x_hat, x_target)\n",
    "    kl_loss = 0.5 * torch.sum(torch.exp(sigma_hat) + torch.pow(mu_hat,2) - torch.ones((1,mu_hat.size()[1])) - mu_hat, axis=1)\n",
    "    return likelihood_loss + kl_loss\n",
    "\n",
    "def train(model, loader_train, optimizer, loader_val, epochs, logger, device, dtype):\n",
    "    \"\"\" \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    - logger: Logger object for logging purpose\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    num_batch = len(list(iter(loader_train)))\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    print('Begin trainning...')\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            mu_hat, sigma_hat, x_hat = model(x)\n",
    "            \n",
    "            loss = beta_vae_loss(mu_hat, sigma_hat, x_hat, x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                logger.writer.add_scalar(\"Loss/train\", loss.item(), e*num_batch+t)\n",
    "                logger.log('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "#         train_acc = check_accuracy(loader_train, 'train', model, device, dtype, logger)\n",
    "#         logger.writer.add_scalar(\"Acc/train\", train_acc, e)        \n",
    "        # get validation loss\n",
    "#         model.eval()\n",
    "#         val_loss = check_accuracy(loader_val, 'val', model, device, dtype, logger)\n",
    "#         logger.writer.add_scalar(\"Acc/valid\", val_acc, e)        \n",
    "#         logger.log()\n",
    "        \n",
    "        # Save model per fixed epoch interval\n",
    "        if e > 0 and e % 10 == 0:\n",
    "            logger.save_model(model,f\"epoch{e}\")\n",
    "#         elif val_acc >= 0.83:\n",
    "#             logger.save_model(model,f\"valacc83-epoch{e}\")\n",
    "#         elif val_acc >= 0.84:\n",
    "#             logger.save_model(model,f\"valacc84-epoch{e}\")\n",
    "    # save final model\n",
    "    logger.save_model(model,f\"epoch{e}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb70ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mu dim: torch.Size([30, 10])\n",
      "Predicted sigma dim: torch.Size([30, 10])\n",
      "Predicted x dim: torch.Size([30, 1, 24, 256])\n",
      "Loss shape: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "mu_pred, sigma_pred, x_pred = vae(torch.zeros(30,1,24,256))\n",
    "\n",
    "print(f'Predicted mu dim: {mu_pred.size()}')\n",
    "print(f'Predicted sigma dim: {sigma_pred.size()}')\n",
    "print(f'Predicted x dim: {x_pred.size()}')\n",
    "\n",
    "loss = beta_vae_loss(mu_pred, sigma_pred, x_pred, torch.ones(30,1,24,256))\n",
    "print(f'Loss shape: {loss.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ec2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin trainning...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d40d4f71819a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-67277a731b96>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, optimizer, loader_val, epochs, logger, device, dtype)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "logger = Logger()\n",
    "logger.set_model_save_location('VAE')\n",
    "seed = 0\n",
    "experiment = f'VAE-seed{seed}'\n",
    "# logger.set_experiment(experiment)\n",
    "\n",
    "batch_size = 16\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size)\n",
    "loader_val = DataLoader(val_data, batch_size=batch_size)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.0001)\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train(vae, loader_train, optimizer, loader_val, 100, logger, device, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_W(W, F, P, S):\n",
    "    return np.floor((W - F + 2*P)/S + 1)\n",
    "\n",
    "W = 256\n",
    "for i in range(3):\n",
    "    W = out_W(W, 6, 2, 2)\n",
    "\n",
    "print(W)\n",
    "print(out_W(W, 3, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5e2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
